{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771cb491",
   "metadata": {},
   "source": [
    "\n",
    "# MAvis Experimentation Notebook\n",
    "\n",
    "This notebook is designed to help you experiment with different search-based methods in AI. You will be tasked to implement different search strategies, both uninformed and informed, and to use this notebook to run benchmarks. It integrates functionalities from your Python modules and the Mavis Level Designer.\n",
    "\n",
    "### Features:\n",
    "- Load and edit levels using the [Mavis Level Designer](https://sebastianrmason.github.io/mavis-level-designer/).\n",
    "- Experiment with search algorithms such as BFS, DFS and more.\n",
    "- Explore heuristics and their impact on the performance of informed search methods.\n",
    "- Visualize search progress and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56a4093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules from your files\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from searchclient.agent_types.classic import * \n",
    "\n",
    "# Import all action classes (used for hardcoding solutions) and actions libraries\n",
    "from searchclient.domains.hospital.actions import (\n",
    "    NoOpAction, MoveAction, PushAction, PullAction, AnyAction, DEFAULT_MAPF_ACTION_LIBRARY, DEFAULT_HOSPITAL_ACTION_LIBRARY\n",
    ")\n",
    "\n",
    "# Import state, goal description and level classes for the MAvis hospital environment\n",
    "from searchclient.domains.hospital.state import HospitalState\n",
    "from searchclient.domains.hospital.goal_description import HospitalGoalDescription\n",
    "from searchclient.domains.hospital.level import HospitalLevel\n",
    "\n",
    "# Import the Graph-Search algorithm\n",
    "from searchclient.search_algorithms.graph_search import graph_search\n",
    "\n",
    "# Import the different search strategies for both uninformed and informed search\n",
    "from searchclient.strategies.bfs import FrontierBFS\n",
    "from searchclient.strategies.dfs import FrontierDFS\n",
    "from searchclient.strategies.bestfirst import FrontierBestFirst, FrontierGreedy, FrontierAStar\n",
    "\n",
    "# Import heuristic classes, to be used in informed search methods\n",
    "from searchclient.domains.hospital.heuristics import (\n",
    "    HospitalZeroHeuristic, HospitalGoalCountHeuristics, HospitalAdvancedHeuristics\n",
    ")\n",
    "\n",
    "# Ensure the environment is set up properly\n",
    "print(\"Modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59682893",
   "metadata": {},
   "source": [
    "\n",
    "## Level Design\n",
    "\n",
    "You can use the [Mavis Level Designer](https://sebastianrmason.github.io/mavis-level-designer/) to create and edit levels.\n",
    "Save the level as a `.lvl` file and upload it in thele `level` folder for experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9b085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial state of the level is:\n",
      "++++++++++\n",
      "+0       +\n",
      "+     ++++\n",
      "+        +\n",
      "+     ++ +\n",
      "+      + +\n",
      "++++++++++\n",
      "\n",
      "The goal description of the level is:\n",
      "((5, 8), '0', True)\n",
      "\n",
      "So agent zero starts at (1, 1) and satisfies the goal at (5, 8)\n"
     ]
    }
   ],
   "source": [
    "# Function to load a level file\n",
    "def load_level_file_from_path(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = list(map(lambda line: line.strip(), lines))\n",
    "        return lines\n",
    "  \n",
    "# Example usage: load_level('path_to_level_file.lvl')\n",
    "level_path = \"levels/MAPF00.lvl\"\n",
    "level_lines = load_level_file_from_path(level_path)\n",
    "level = HospitalLevel.parse_level_lines(level_lines)\n",
    "\n",
    "# We can access the initial state of the level using the following code\n",
    "initial_state = HospitalState(level, level.initial_agent_positions, level.initial_box_positions)\n",
    "\n",
    "# We can access the goal description of the level using the following code\n",
    "goal_description = HospitalGoalDescription(level, level.box_goals + level.agent_goals)\n",
    "\n",
    "print('The initial state of the level is:')\n",
    "print(initial_state)\n",
    "\n",
    "print('\\nThe goal description of the level is:')\n",
    "print(goal_description) # which tells us where the level objects (like boxes and agents) should be placed to satisfy the goal\n",
    "print('\\nSo agent zero starts at {} and satisfies the goal at {}'.format(level.initial_agent_positions[0][0], goal_description.agent_goals[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a010568",
   "metadata": {},
   "source": [
    "## Rendering states\n",
    "Visualizing the states of your environment is an essential step in understanding the intricacies of your problem space. By rendering individual states, you can gain a better grasp of the initial setup, intermediate configurations, and goal states of your system. This approach not only helps debug your environment but also lays a foundation for interpreting plans and strategies more effectively.\n",
    "\n",
    "Rendering states can be accomplished easily using the `render_state()` function in the PyGame rendering script. This function takes a level and single state as input and visualizes it, allowing you to observe key attributes and spatial layouts. For instance, you can analyze agent positions, obstacles, or other relevant features specific to your problem.\n",
    "\n",
    "The function will save the rendered state as a `.png` file. Unless specified, the image will be saved as `rendered_state.png`. Below is an example on how to use it where we just save the initial state of the level above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feeac4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "State rendered and saved to give_me_a_name.png\n",
      "++++++++++\n",
      "+0       +\n",
      "+     ++++\n",
      "+        +\n",
      "+     ++ +\n",
      "+      + +\n",
      "++++++++++\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from renderState import *\n",
    "\n",
    "# Render some state of the level (here the initial state)\n",
    "render_state(level_path=level_path, state=initial_state, output_path='give_me_a_name')\n",
    "\n",
    "# So the state looks like this in .txt format (what the computer uses):\n",
    "print(initial_state)\n",
    "\n",
    "# And the initial state looks like this in .png:\n",
    "# You can either show the image in the notebook or open it in a new window\n",
    "img = Image.open('give_me_a_name.png')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f77c70-fbdd-4dba-96d4-bc61dab5f799",
   "metadata": {},
   "source": [
    "## Rendering plans\n",
    "Rendering your environment is a big part of gaining core insights about the theoretical challenges of certain problems. It helps you gain a conceptual understanding of your chosen approach much faster, and can also aid you in chosing your strategy. Below, we show you an easy way to send the plan found by graph search to the PyGame rendering script.\n",
    "\n",
    "All we have to do is convert the plan returned by graph search to a string using the `convert_plan_to_string()` utility function, and then pass it to the `renderMAvis.py` script. Note that the first execution of the `render_plan()` function may take some time, but it typically runs much faster on subsequent attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4759ea-a320-4416-acd6-507d26e24641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_plan(level_path, plan, strategy_name, heuristic_name, num_generated, elapsed_time, sol_length):\n",
    "\n",
    "    str_plan = convert_plan_to_string(plan) #convert the plan to a string\n",
    "\n",
    "    # this just makes sure that the meta information is displayed correctly in the visualization\n",
    "    if strategy_name == 'greedy' or strategy_name == 'astar':\n",
    "        strategy_name_pygame = strategy_name + ' w. ' + heuristic_name\n",
    "    else:\n",
    "        strategy_name_pygame = strategy_name\n",
    "    \n",
    "    subprocess.run([\"python3\", \n",
    "                    \"renderMAvis.py\", \n",
    "                    \"--level\", level_path, \n",
    "                    \"--plan\", str_plan, \n",
    "                    \"--search_strategy\", strategy_name_pygame, \n",
    "                    \"--num_generated\", str(num_generated), \n",
    "                    \"--time_elapsed\", str(elapsed_time), \n",
    "                    \"--sol_length\", str(sol_length)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5102a-50fb-4629-8178-3fb46174da26",
   "metadata": {},
   "source": [
    "We can use the `render_plan` function to hardcode a solution to our problem. Since you will later use Graph-Search to automatically find plans, you can use this to familiarize yourself with the client, the actions class and other classes of the MAvis environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35252cf9-8e48-4519-87ce-3cdc1b29af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of a plan. A plan is a list of list of actions, where an action is an instance from searchclient.domains.hospital.actions\n",
    "# The first axis of the list corresponds to a timestep in the plan. \n",
    "# Each element of the innermost list corresponds to an action of a different agent. \n",
    "# Check the documentation of graph_seach.py for more information!\n",
    "\n",
    "# Hardcode your solution here!\n",
    "#hardcoded_plan = None\n",
    "hardcoded_plan = [[MoveAction(\"S\")], \n",
    "                  [MoveAction(\"S\")], [MoveAction(\"E\")], \n",
    "                  [MoveAction(\"E\")], [MoveAction(\"E\")], \n",
    "                  [MoveAction(\"E\")], [MoveAction(\"E\")], \n",
    "                  [MoveAction(\"E\")], [MoveAction(\"E\")],\n",
    "                  [MoveAction(\"S\")], [MoveAction(\"S\")],\n",
    "                  [MoveAction(\"S\")],  [NoOpAction()]]\n",
    "\n",
    "render_plan(level_path, hardcoded_plan, \"Hardcoded sol\", None, len(hardcoded_plan), \"0.0\", len(hardcoded_plan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749eb505",
   "metadata": {},
   "source": [
    "## Executing Search Algorithms\n",
    "\n",
    "In the following code we will be running the Graph-Search algorithm using a specified search strategy. \n",
    "\n",
    "You will have to implement the Graph-Search yourself after what you have seen in class. The implementation for the Bredth First Search (BFS) frontier is already available and you can use it as inspiration for coding other search strategies in the future.\n",
    "\n",
    "Until Graph-Search is implemented, you are only able to hardcode a plan. Later on you can use the following pipeline to run experiments for the Mavis assignments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea2da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the search algorithm, we need to define the action set and the action library\n",
    "# Use this library for pure pathfinding problems\n",
    "action_library = DEFAULT_MAPF_ACTION_LIBRARY\n",
    "\n",
    "# Use this library for sokoban-like problems (includes Push and Pull actions)\n",
    "#action_library = DEFAULT_HOSPITAL_ACTION_LIBRARY\n",
    "\n",
    "# Every agent will have the same action set\n",
    "action_set = [action_library] * level.num_agents\n",
    "\n",
    "# In order to run Graph-Search, we need to specify the initial state, action set, goal description, and frontier \n",
    "\n",
    "# If needed, we need to specify and fetch a heuristic function before initializing the frontier (informed search) \n",
    "# When adding new heuristics, remember to update the dictionary! \n",
    "# Use a string that matches the name of the heuristic function in the heuristics.py file\n",
    "heuristic_name = \"zero\" \n",
    "heuristic = {\n",
    "        'zero': HospitalZeroHeuristic,\n",
    "        'goalcount': HospitalGoalCountHeuristics,\n",
    "        'advanced': HospitalAdvancedHeuristics,\n",
    "    }.get(heuristic_name, HospitalZeroHeuristic)() # make sure you understand what .get() does\n",
    "\n",
    "\n",
    "# Finally, let's pick the search strategy and fetch the relevant frontier\n",
    "strategy_name = \"bfs\" \n",
    "frontier = {\n",
    "        'bfs': FrontierBFS,\n",
    "        'dfs': FrontierDFS,\n",
    "        'astar': lambda: FrontierAStar(heuristic),\n",
    "        'greedy': lambda: FrontierGreedy(heuristic)\n",
    "    }.get(strategy_name, FrontierBFS)() # make sure you understand what .get() does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "344c495f-6844-436a-a7db-1ca890bcf913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning successful: True\n",
      "Plan: [[Move(E)], [Move(S)], [Move(S)], [Move(E)], [Move(E)], [Move(E)], [Move(E)], [Move(E)], [Move(E)], [Move(S)], [Move(S)]]\n",
      "Solution length: 11\n",
      "Number of states generated: 11\n",
      "Elapsed time: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Expanded:       11, #Frontier:        0, #Generated:       11, Time: 0,000 s, Memory: 104,90 MB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now that we have defined the initial state, action set, goal description, and frontier, we can run the search algorithm\n",
    "planning_success, plan, num_generated, elapsed_time = graph_search(initial_state, action_set, goal_description, frontier)\n",
    "\n",
    "# The graph search function returns the following:\n",
    "print('Planning successful:', planning_success)\n",
    "print('Plan:', plan)\n",
    "print('Solution length:', len(plan))\n",
    "print('Number of states generated:', num_generated)\n",
    "print('Elapsed time:', elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb7fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_plan(level_path, plan, strategy_name, heuristic, num_generated, elapsed_time, len(plan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1420d-7f79-4879-8eec-2e3d56d41599",
   "metadata": {},
   "source": [
    "## Running multiple trials and statistical analysis of performance\n",
    "\n",
    "In order to make more principled statements over the different algorithms' performance, we will provide you a pipeline to run $n$-trials over a given level. This will allow you to consider the average performance and their statistics instead of drawing conclusions from a singular example. \n",
    "\n",
    "**NOTE:** for complex levels with longer runtimes, it might not be feasible to run a high number of trials! Take this into consideration when running your experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caac2811-3319-4033-bf19-1ecef909fede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial state of the level is:\n",
      "++++++++++\n",
      "+0       +\n",
      "+     ++++\n",
      "+        +\n",
      "+     ++ +\n",
      "+      + +\n",
      "++++++++++\n",
      "\n",
      "The goal description of the level is:\n",
      "((5, 8), '0', True)\n",
      "\n",
      "So agent zero starts at (1, 1) and satisfies the goal at (5, 8)\n"
     ]
    }
   ],
   "source": [
    "# For easiness of use, let's redifine and reload everything  \n",
    "level_path = \"levels/MAPF00.lvl\"\n",
    "level_lines = load_level_file_from_path(level_path)\n",
    "level = HospitalLevel.parse_level_lines(level_lines)\n",
    "\n",
    "# We can access the initial state of the level using the following code\n",
    "initial_state = HospitalState(level, level.initial_agent_positions, level.initial_box_positions)\n",
    "\n",
    "# We can access the goal description of the level using the following code\n",
    "goal_description = HospitalGoalDescription(level, level.box_goals + level.agent_goals)\n",
    "\n",
    "print('The initial state of the level is:')\n",
    "print(initial_state)\n",
    "\n",
    "print('\\nThe goal description of the level is:')\n",
    "print(goal_description) # which tells us where the level objects (like boxes and agents) should be placed to satisfy the goal\n",
    "print('\\nSo agent zero starts at {} and satisfies the goal at {}'.format(level.initial_agent_positions[0][0], goal_description.agent_goals[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c751d41-b646-4333-b9e1-d54f755fc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running the search algorithm, we need to define the action set and the action library\n",
    "# Use this library for pure pathfinding problems\n",
    "action_library = DEFAULT_MAPF_ACTION_LIBRARY\n",
    "\n",
    "# Use this library for sokoban-like problems (includes Push and Pull actions)\n",
    "#action_library = DEFAULT_HOSPITAL_ACTION_LIBRARY\n",
    "\n",
    "# Every agent will have the same action set\n",
    "action_set = [action_library] * level.num_agents\n",
    "\n",
    "# In order to run Graph-Search, we need to specify the initial state, action set, goal description, and frontier \n",
    "\n",
    "# If needed, we need to specify and fetch a heuristic function before initializing the frontier (informed search) \n",
    "# When adding new heuristics, remember to update the dictionary! \n",
    "# Use a string that matches the name of the heuristic function in the heuristics.py file\n",
    "heuristic_name = \"zero\" \n",
    "heuristic = {\n",
    "        'zero': HospitalZeroHeuristic,\n",
    "        'goalcount': HospitalGoalCountHeuristics,\n",
    "        'advanced': HospitalAdvancedHeuristics,\n",
    "    }.get(heuristic_name, HospitalZeroHeuristic)() # make sure you understand what .get() does\n",
    "\n",
    "\n",
    "# Finally, let's pick the search strategy and fetch the relevant frontier\n",
    "strategy_name = \"dfs\" \n",
    "frontier = {\n",
    "        'bfs': FrontierBFS,\n",
    "        'dfs': FrontierDFS,\n",
    "        'astar': lambda: FrontierAStar(heuristic),\n",
    "        'greedy': lambda: FrontierGreedy(heuristic)\n",
    "    }.get(strategy_name, FrontierBFS)() # make sure you understand what .get() does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15f67ce0-c131-494e-b813-1bbd002dcff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4231c7bfc16d47e8a37757483d51865f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average solution legth: 13.4\n",
      "Solution length variance : 3.8400000000000007\n",
      "Average number of states generated: 20.9\n",
      "Number of states generated variance : 11.690000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#Expanded:       15, #Frontier:        9, #Generated:       24, Time: 0,002 s, Memory: 105,47 MB\n",
      "\n",
      "\n",
      "#Expanded:       15, #Frontier:        7, #Generated:       22, Time: 0,001 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       11, #Frontier:        7, #Generated:       18, Time: 0,000 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       11, #Frontier:        6, #Generated:       17, Time: 0,002 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       11, #Frontier:        5, #Generated:       16, Time: 0,000 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       15, #Frontier:        9, #Generated:       24, Time: 0,002 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       15, #Frontier:       10, #Generated:       25, Time: 0,000 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       15, #Frontier:       10, #Generated:       25, Time: 0,000 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       11, #Frontier:        6, #Generated:       17, Time: 0,000 s, Memory: 105,48 MB\n",
      "\n",
      "\n",
      "#Expanded:       15, #Frontier:        6, #Generated:       21, Time: 0,002 s, Memory: 105,49 MB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_trials = 10\n",
    "\n",
    "plans, sol_lengths, generated, elapsed = [], [], [], []\n",
    "for n in tqdm(range(n_trials)):\n",
    "    planning_success, plan, num_generated, elapsed_time = graph_search(initial_state, action_set, goal_description, frontier)\n",
    "    plans.append(plan)\n",
    "    sol_lengths.append(len(plan))\n",
    "    generated.append(int(num_generated))\n",
    "    elapsed.append(elapsed_time)\n",
    "\n",
    "\n",
    "# The graph search function returns the following:\n",
    "print('Average solution legth:', np.mean(sol_lengths))\n",
    "print('Solution length variance :', np.var(sol_lengths))\n",
    "print('Average number of states generated:', np.mean(generated))\n",
    "print('Number of states generated variance :', np.var(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e67df5ef-485d-433e-a401-1ecc67659883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to visualize the i-th trial\n",
    "\n",
    "# Select trial to render\n",
    "index_to_render = 2\n",
    "\n",
    "# Render trial\n",
    "render_plan(\n",
    "    level_path,\n",
    "    plans[index_to_render], \n",
    "    strategy_name, \n",
    "    heuristic, \n",
    "    generated[index_to_render],\n",
    "    elapsed[index_to_render], \n",
    "    sol_lengths[index_to_render]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
